{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to ~\\tensorflow_datasets\\fashion_mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c649a5e70341e5b5ae31ea0ba06c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c82b6d2d8e429a88a3209616da2fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb805b2cf08c491ea37a5d301bf3c241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3ede44642541c4a1ecf29f7f5311d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba07ab881b6410199b61f59c9f11935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbca9812fdaf47b3b48f1edaafc2d9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling ~\\tensorflow_datasets\\fashion_mnist\\3.0.1.incompleteIRDQMN\\fashion_mnist-train.tfrecord*...:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a670b2113544ddf9ceef1bab5f4f061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a105448ee19d41a5b086961ed66b47ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling ~\\tensorflow_datasets\\fashion_mnist\\3.0.1.incompleteIRDQMN\\fashion_mnist-test.tfrecord*...:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset fashion_mnist downloaded and prepared to ~\\tensorflow_datasets\\fashion_mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset = tfds.load(\"fashion_mnist\", split=\"train\")\n",
    "\n",
    "def convert(row):\n",
    "    image = tf.image.convert_image_dtype(row[\"image\"], tf.float32)\n",
    "    label = tf.cast(row[\"label\"], tf.float32)\n",
    "    return image, label\n",
    "\n",
    "batch_size = 32\n",
    "dataset = dataset.map(convert).batch(batch_size).prefetch(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#생성기 정의\n",
    "def get_generator(latent_dimension):\n",
    "    #조건 서브 네트워크 : 조건을 히든 표현으로 인코딩\n",
    "    condition = tf.keras.layers.Input((1,))\n",
    "    net = tf.keras.layers.Dense(32, activation=tf.nn.elu)(condition)\n",
    "    net = tf.keras.layers.Dense(64, activation=tf.nn.elu)(net)\n",
    "    #히든 조건 표현을 노이즈와 업샘플에 연결\n",
    "    noise = tf.keras.layers.Input(latent_dimension)\n",
    "    inputs = tf.keras.layers.Concatenate()([noise, net])\n",
    "    # Convert inputs from (batch_size, latent_dimension +1)\n",
    "    #(batch)size, latent_dimension + 1)인 inputs를\n",
    "    #컨볼류션을 사용할 수 있는 4차원 텐서로 변경\n",
    "    inputs = tf.keras.layers.Reshape((1,1, inputs.shape[-1]))(inputs)\n",
    "    depth = 128\n",
    "    kernel_size = 5\n",
    "    net = tf.keras.layers.Conv2DTranspose(\n",
    "        depth, kernel_size,\n",
    "        padding=\"valid\",\n",
    "        strides=1,\n",
    "        activation=tf.nn.relu(inputs) # 5X5\n",
    "    )\n",
    "    net = tf.keras.layers.Conv2DTranspose(\n",
    "        depth//2, kernel_size,\n",
    "        padding=\"valid\",\n",
    "        strides=1,\n",
    "        activation=tf.nn.relu(inputs) # 13X13\n",
    "    )\n",
    "    net = tf.keras.layers.Conv2DTranspose(\n",
    "        depth//4, kernel_size,\n",
    "        padding=\"valid\",\n",
    "        strides=1,\n",
    "        activation=tf.nn.relu,\n",
    "        use_bias = False )(net) #29X29\n",
    "    #28X28X1 출력을 얻기 위해 2x2 커널과의 표준 컨볼류션\n",
    "    #이미지가 [0,1] 범위에 있기 때문에 출력은 sigmoid를 사용한다.\n",
    "\n",
    "    net = tf.keras.layers.Conv2D(\n",
    "        1,2,\n",
    "        padding = \"valid\",\n",
    "        strides = 1,\n",
    "        activation = tf.nn.sigmoid,\n",
    "        use_bias= False)(net)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[noise, condition], outputs=net)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#판별기 정의\n",
    "def get_Discriminator():\n",
    "    #인코더 서브네트워크: 피처 벡터를 얻는 피처 추출기\n",
    "    image = tf.keras.layers.Input((28,28,1))\n",
    "    depth = 32\n",
    "    kernel_size = 3\n",
    "    net = tf.keras.layers.Conv2D(\n",
    "        depth, kernel_size,\n",
    "        padding=\"same\",\n",
    "        strides = 2,\n",
    "        activation=tf.nn.relu)(image) #14x14x32\n",
    "    net = tf.keras.layers.Conv2D(\n",
    "        depth*2, kernel_size,\n",
    "        padding=\"same\",\n",
    "        strides = 2,\n",
    "        activation=tf.nn.relu)(net) #7x7x64\n",
    "    net = tf.keras.layers.Conv2D(\n",
    "        depth*3, kernel_size,\n",
    "        padding=\"same\",\n",
    "        strides = 2,\n",
    "        activation=tf.nn.relu)(net) #4x4x96\n",
    "    feature_vector = tf.keras.layers.Flatten()(net) #4*4*96\n",
    "    #조건에 관한 히든 표현 만들기\n",
    "    condition = tf.keras.layers.Input((1,))\n",
    "    hidden = tf.keras.layers.Dense(32, activation=tf.nn.elu)(condition)\n",
    "    hidden = tf.keras.layers.Dense(64, activation=tf.nn.elu)(hidden)\n",
    "    # 피처 벡터와 히든 레이블 표현 연결\n",
    "    out = tf.keras.layers.Concatenate()([feature_vector, hidden])\n",
    "    # 단일 선형 뉴런으로 이뤄진 최종 분류 레이어 추가\n",
    "    out = tf.keras.layers.Dense(128, activation=tf.nn.relu)(out)\n",
    "    out = tf.keras.layers.Dense(1)(out)\n",
    "    model = tf.keras.Model(inputs = [image, condition], outputs = out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#적대적 훈련 과정\n",
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def d_loss(d_real, d_fake):\n",
    "    '''판별기 손실함수'''\n",
    "    return bce(tf.ones_like(d_real), d_real) + bce(tf.zeros_like(d_fake), d_fake)\n",
    "def g_loss(generated_output):\n",
    "    '''생성기 손실함수'''\n",
    "    return bce(tf.ones_like(generated_output), generated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer \"tf.keras.activations.get\" (type TFOpLambda).\n\nCould not interpret activation function identifier: Tensor(\"Placeholder:0\", shape=(None, 1, 1, 164), dtype=float32)\n\nCall arguments received:\n  • identifier=tf.Tensor(shape=(None, 1, 1, 164), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\bitcamp\\EI\\jupyter\\book_example\\gan_conditional.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000005?line=0'>1</a>\u001b[0m latent_dimension \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000005?line=1'>2</a>\u001b[0m G \u001b[39m=\u001b[39m get_generator(latent_dimension)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000005?line=2'>3</a>\u001b[0m D \u001b[39m=\u001b[39m get_Discriminator()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000005?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtraion\u001b[39m():\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000005?line=5'>6</a>\u001b[0m     \u001b[39m#옵티마이저 및 학습 연산을 정의한다.\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\EI\\jupyter\\book_example\\gan_conditional.ipynb Cell 2'\u001b[0m in \u001b[0;36mget_generator\u001b[1;34m(latent_dimension)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000001?line=12'>13</a>\u001b[0m depth \u001b[39m=\u001b[39m \u001b[39m128\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000001?line=13'>14</a>\u001b[0m kernel_size \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000001?line=14'>15</a>\u001b[0m net \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mConv2DTranspose(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000001?line=15'>16</a>\u001b[0m     depth, kernel_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000001?line=16'>17</a>\u001b[0m     padding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mvalid\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000001?line=17'>18</a>\u001b[0m     strides\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000001?line=18'>19</a>\u001b[0m     activation\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mrelu(inputs) \u001b[39m# 5X5\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000001?line=19'>20</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000001?line=20'>21</a>\u001b[0m net \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mConv2DTranspose(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000001?line=21'>22</a>\u001b[0m     depth\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m, kernel_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000001?line=22'>23</a>\u001b[0m     padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000001?line=23'>24</a>\u001b[0m     strides\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000001?line=24'>25</a>\u001b[0m     activation\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mrelu(inputs) \u001b[39m# 13X13\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000001?line=25'>26</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000001?line=26'>27</a>\u001b[0m net \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mConv2DTranspose(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000001?line=27'>28</a>\u001b[0m     depth\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m4\u001b[39m, kernel_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000001?line=28'>29</a>\u001b[0m     padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000001?line=29'>30</a>\u001b[0m     strides\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000001?line=30'>31</a>\u001b[0m     activation\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mrelu,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bitcamp/EI/jupyter/book_example/gan_conditional.ipynb#ch0000001?line=31'>32</a>\u001b[0m     use_bias \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m )(net) \u001b[39m#29X29\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\mibot\\lib\\site-packages\\keras\\layers\\convolutional.py:1229\u001b[0m, in \u001b[0;36mConv2DTranspose.__init__\u001b[1;34m(self, filters, kernel_size, strides, padding, output_padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m   1205\u001b[0m              filters,\n\u001b[0;32m   1206\u001b[0m              kernel_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1220\u001b[0m              bias_constraint\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1221\u001b[0m              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1222\u001b[0m   \u001b[39msuper\u001b[39m(Conv2DTranspose, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[0;32m   1223\u001b[0m       filters\u001b[39m=\u001b[39mfilters,\n\u001b[0;32m   1224\u001b[0m       kernel_size\u001b[39m=\u001b[39mkernel_size,\n\u001b[0;32m   1225\u001b[0m       strides\u001b[39m=\u001b[39mstrides,\n\u001b[0;32m   1226\u001b[0m       padding\u001b[39m=\u001b[39mpadding,\n\u001b[0;32m   1227\u001b[0m       data_format\u001b[39m=\u001b[39mdata_format,\n\u001b[0;32m   1228\u001b[0m       dilation_rate\u001b[39m=\u001b[39mdilation_rate,\n\u001b[1;32m-> 1229\u001b[0m       activation\u001b[39m=\u001b[39mactivations\u001b[39m.\u001b[39;49mget(activation),\n\u001b[0;32m   1230\u001b[0m       use_bias\u001b[39m=\u001b[39muse_bias,\n\u001b[0;32m   1231\u001b[0m       kernel_initializer\u001b[39m=\u001b[39minitializers\u001b[39m.\u001b[39mget(kernel_initializer),\n\u001b[0;32m   1232\u001b[0m       bias_initializer\u001b[39m=\u001b[39minitializers\u001b[39m.\u001b[39mget(bias_initializer),\n\u001b[0;32m   1233\u001b[0m       kernel_regularizer\u001b[39m=\u001b[39mregularizers\u001b[39m.\u001b[39mget(kernel_regularizer),\n\u001b[0;32m   1234\u001b[0m       bias_regularizer\u001b[39m=\u001b[39mregularizers\u001b[39m.\u001b[39mget(bias_regularizer),\n\u001b[0;32m   1235\u001b[0m       activity_regularizer\u001b[39m=\u001b[39mregularizers\u001b[39m.\u001b[39mget(activity_regularizer),\n\u001b[0;32m   1236\u001b[0m       kernel_constraint\u001b[39m=\u001b[39mconstraints\u001b[39m.\u001b[39mget(kernel_constraint),\n\u001b[0;32m   1237\u001b[0m       bias_constraint\u001b[39m=\u001b[39mconstraints\u001b[39m.\u001b[39mget(bias_constraint),\n\u001b[0;32m   1238\u001b[0m       \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1240\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_padding \u001b[39m=\u001b[39m output_padding\n\u001b[0;32m   1241\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_padding \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\mibot\\lib\\site-packages\\keras\\layers\\core\\tf_op_layer.py:107\u001b[0m, in \u001b[0;36mKerasOpDispatcher.handle\u001b[1;34m(self, op, args, kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39m\"\"\"Handle the specified operation with the specified arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[0;32m    105\u001b[0m     \u001b[39misinstance\u001b[39m(x, keras_tensor\u001b[39m.\u001b[39mKerasTensor)\n\u001b[0;32m    106\u001b[0m     \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten([args, kwargs])):\n\u001b[1;32m--> 107\u001b[0m   \u001b[39mreturn\u001b[39;00m TFOpLambda(op)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    108\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mNOT_SUPPORTED\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\mibot\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\mibot\\lib\\site-packages\\keras\\activations.py:602\u001b[0m, in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    600\u001b[0m   \u001b[39mreturn\u001b[39;00m identifier\n\u001b[0;32m    601\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 602\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    603\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCould not interpret activation function identifier: \u001b[39m\u001b[39m{\u001b[39;00midentifier\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Exception encountered when calling layer \"tf.keras.activations.get\" (type TFOpLambda).\n\nCould not interpret activation function identifier: Tensor(\"Placeholder:0\", shape=(None, 1, 1, 164), dtype=float32)\n\nCall arguments received:\n  • identifier=tf.Tensor(shape=(None, 1, 1, 164), dtype=float32)"
     ]
    }
   ],
   "source": [
    "latent_dimension = 100\n",
    "G = get_generator(latent_dimension)\n",
    "D = get_Discriminator()\n",
    "\n",
    "def traon():\n",
    "    #옵티마이저 및 학습 연산을 정의한다.\n",
    "    optimizer = tf.keras.optimizers.Adam(1e-5)\n",
    "    @tf.function\n",
    "    def train_step(image, label):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            noise_vector = tf.random.normal(\n",
    "                mean=0, stddev=1,\n",
    "                shape=(image.shape[0], latent_dimension))\n",
    "            #생성기에서 샘풀링\n",
    "            fake_data = G([noise_vector, label])\n",
    "            # D 손실 계산\n",
    "            d_fake_data = D([fake_data, label])\n",
    "            d_real_data = D([image, label])\n",
    "            d_loss_value = d_loss(d_real_data, d_fake_data)\n",
    "            #G 손실 계산\n",
    "            g_loss_value = g_loss(d_fake_data)\n",
    "            #이제 손실을 계산했으므로 그래디언트를 계산하고\n",
    "            #네트워크를 최적화 할 수 있다.\n",
    "            d_gradients = tape.gradient(d_loss_value, D.trainable_variables)\n",
    "            g_gradients = tape.gradient(g_loss_value, G.trainable_variables)\n",
    "            # 테이프를 영구로 정의했기 때문에 테이프 삭제\n",
    "            del tape\n",
    "            optimizer.apply_gradients(zip(d_gradients, D.trainable_variables))\n",
    "            optimizer.apply_gradients(zip(g_gradients, G.trainable_variables))\n",
    "            return g_loss_value, d_loss_value, fake_data[0], label[0]\n",
    "\n",
    "epochs = 10\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for image, label in dataset:\n",
    "        g_loss_value, d_loss_value, generated, condition = train_step(image, label)\n",
    "\n",
    "        print(\"epoch\", epoch, \"complete\")\n",
    "        print(\"loss:\", g_loss_value, \"d_loss:\", d_loss_value)\n",
    "        print(\"condition\", info.features['label'].int2str(\n",
    "            tf.squeeze(tf.cast(condition, tf.int32)).numpy()))\n",
    "        plt.imshow(tf.squeeze(generated).numpy(), cmap='gray')\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('mibot')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e3d47cc14d0a7d841567c666b1bce259a39d7b78ffe0f6911e5c2094b850179"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
